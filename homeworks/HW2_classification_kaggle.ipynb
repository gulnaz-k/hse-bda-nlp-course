{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-fV6fHbe8wrX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ДЗ2. Семантическая близость (kaggle-соревнование)"
      ],
      "metadata": {
        "id": "Az97IF_NEn--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Введение"
      ],
      "metadata": {
        "id": "cly4qgGk_GSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом задании вы будете решать задачу семантической релевантности пар постов и отправлять предсказания на Kaggle.\n",
        "\n",
        "**Цель:** построить модель, которая по паре постов предсказывает, насколько тексты близки друг другу по смыслу.\n",
        "\n",
        "Вся информация по заданию, данным, а также доступ к ним - только через закрытое соревнование.\n",
        "\n",
        "Метрика качества: **Weighted F1-score** по всем классам.\n",
        "\n",
        "Подробная разбалловка за ноутбук и соревнование описана ниже.\n"
      ],
      "metadata": {
        "id": "_nkv8Hpl0LWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вот несколько правил, который помогут нам сделать работу приятнее и продуктивнее:\n",
        "\n",
        "- Можно использовать любые свободные источники с обязательным указанием ссылки на них. Если в работе вы используете генеративные модели, их указание обязательно. Иначе баллы за работу могут быть снижены. Также следите за оригинальностью: генеративного кода должно быть не более 60% работы.\n",
        "- Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
        "- Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе.\n",
        "\n",
        "**Формат сдачи**\n",
        "\n",
        "Задания сдаются через систему LMS. Посылка должна содержать:\n",
        "\n",
        "- ноутбук `homework-02-Username.ipynb`  \n",
        "  где `Username` - ваша фамилия латиницей, без пробелов (например, `homework-02-Ivanov.ipynb`);\n",
        "- комментарий к посылке, в котором укажите ваш Kaggle nicknamе (по нему мы будем искать вас в лидерборде соревнования).\n",
        "\n",
        "> Если вы используете дополнительные файлы (скрипты, сохранённые веса модели и т.п.), то либо:\n",
        "> - делайте так, чтобы ноутбук мог их скачать сам (например, с Kaggle / Google Drive),  \n",
        "> - либо приложите их архивом и явно опишите в ноутбуке, как ими пользоваться.  \n",
        "> В идеале всё должно работать без ручных правок путей."
      ],
      "metadata": {
        "id": "R4fEC2Lq30Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Об оценивании\n",
        "\n",
        "В этом домашнем задании у вас есть два источника баллов:\n",
        "\n",
        "1. Баллы за ноутбук (за код, воспроизводимость и эксперименты)\n",
        "2. Баллы за результат на Kaggle (Private leaderboard)\n",
        "\n",
        "Важно: баллы за соревнование начисляются только при сданном ноутбуке.\n",
        "\n",
        "**1) Баллы за ноутбук (максимум 8.0 баллов)**\n",
        "\n",
        "За реализацию пайплайна в этом ноутбуке можно получить **до 8 баллов**.\n",
        "\n",
        "Минимальная работа - 5.0 баллов.\n",
        "Вы получаете 5 баллов, если ноутбук:\n",
        "\n",
        "* запускается без ручных правок,\n",
        "* делает подготовку данных,\n",
        "* обучает/применяет модель (baseline),\n",
        "* формирует корректный `submission.csv`,\n",
        "* и вы сдаёте этот ноутбук в LMS.\n",
        "\n",
        "Дальше можно добрать баллы:\n",
        "\n",
        "* **+1.0 балл** - если вы преодолели минимальный бенчмарк на Kaggle (Public score ≥ `B_min`).\n",
        "* **+1.0 балл** - за объёмные эксперименты: осмысленные сравнения подходов (например, несколько моделей/фич/стратегий, таблица результатов + короткие выводы что помогло и почему).\n",
        "* **+1.0 балл** - если вы преодолели сильный бенчмарк на Kaggle (Public score ≥ `B_strong`).\n",
        "\n",
        "> Пороговые значения **`B_min`** и **`B_strong`** будут указаны на странице Kaggle.\n",
        "\n",
        "**2) Баллы за соревнование на Kaggle (до 2.0 баллов)**\n",
        "\n",
        "Дополнительные баллы начисляются по вашему лучшему результату на приватном лидерборде (*Private leaderboard*) и только если у вас сдан воспроизводимый ноутбук.\n",
        "\n",
        "Баллы за соревнование состоят из двух независимых бонусов:\n",
        "\n",
        "A. Бонус за попадание в топ-10 (дополнительно):\n",
        "\n",
        "* Если вы попали в топ-10 по Private leaderboard -> **+1.0 балл**\n",
        "\n",
        "B. Бонус за попадание в топ-2% (дополнительно):\n",
        "\n",
        "* Если вы попали в топ-2% по Private leaderboard -> **+1.0 балл**\n",
        "\n",
        "Таким образом:\n",
        "\n",
        "* Участник из топ-10 получит **+1**,\n",
        "* участник из топ-2% получит ещё **+1**,\n",
        "* участники, которые одновременно в топ-10 и топ-2%, получат **+2**.\n",
        "\n",
        "> Примечание: топ-2% считается от числа участников, сдавших хотя бы один валидный сабмит. Если 2% - это дробное число, округляем вверх (например, при 120 участниках топ-2% = топ-3 места).\n",
        "\n",
        "**Суммарно за ДЗ2**\n",
        "\n",
        "* Максимум за ноутбук: 8.0\n",
        "* Максимум за Kaggle-бонусы: 2.0\n",
        "* Максимальная оценка за ДЗ2: 10.0\n"
      ],
      "metadata": {
        "id": "BF2QBaf6MLDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Требование к воспроизводимости\n",
        "\n",
        "В конце ноутбука у вас должен быть отдельный блок \"Воспроизводимый пайплайн\" с одной кодовой ячейкой, которая из исходных данных собирает финальный `submission.csv`в для Kaggle.\n",
        "\n",
        "Именно эта ячейка должна воспроизводить ваш итоговый результат. Если финальная модель обучалась долго, допускается загружать заранее сохранённые веса, а не обучать модель с нуля."
      ],
      "metadata": {
        "id": "EWaRVD3LcxQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Основная часть работы (5 баллов)"
      ],
      "metadata": {
        "id": "2KY17gOr-6Dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сеттинг и данные"
      ],
      "metadata": {
        "id": "KP9EFFGE-4Wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Описание данных доступно на Kaggle.\n",
        "\n",
        "Вы можете использовать данные, которые загружены в самом соревновании, либо воспользоваться теми, что заботливо сложили на Google Диск. Ссылка на Google Диск так же в разделе \"данные\" на Kaggle."
      ],
      "metadata": {
        "id": "_GGy1wAj_YB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Как получить файл по ссылке с Google Диска в Colab?\n",
        "\n",
        "# Устанавливаем gdown\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "# Если ссылка выглядит так:\n",
        "# https://drive.google.com/file/d/FILE_ID/view?usp=sharing\n",
        "# то FILE_ID - это часть между /d/ и /view.\n",
        "\n",
        "FILE_ID = \"ВСТАВЬТЕ_ЗДЕСЬ_FILE_ID\"  # например, \"1LmQ6xJLnp7gKgjoFsxарввrKLSa1\"\n",
        "OUTPUT_NAME = \"items.parquet\"       # как назвать скачанный файл\n",
        "\n",
        "gdown.download(id=FILE_ID, output=OUTPUT_NAME, quiet=False)\n",
        "\n",
        "# После этого файл можно читать как обычный локальный:\n",
        "# items = pd.read_parquet(\"items.parquet\")"
      ],
      "metadata": {
        "id": "vV6llVFDBJZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 1. Подготовка данных и первичный EDA (1 балл)"
      ],
      "metadata": {
        "id": "Fs7BNMW1BYhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цель: убедиться, что данные читаются корректно, и понять базовые свойства выборки.\n",
        "\n",
        "Что нужно сделать:\n",
        "\n",
        "1. Загрузить необходимые четыре файла.\n",
        "2. Посчитать размеры таблиц, проверить типы столбцов.\n",
        "3. Посмотреть распределение классов `result` в train (`value_counts` и `value_counts(normalize=True)`).\n",
        "4. Вывести несколько примеров пар постов: замерджить train с items и посмотреть, как выглядят тексты для разных классов.\n",
        "\n",
        "Результат: у вас есть базовое понимание, что за данные и какие классы вы предсказываете."
      ],
      "metadata": {
        "id": "BCvWonzTBfuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# базовое исследование данных и распределений\n",
        "# your code here ฅ^•ﻌ•^ฅ"
      ],
      "metadata": {
        "id": "4g6Y3xDyBwQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 2. Сборка датасета пар (1 балл)\n"
      ],
      "metadata": {
        "id": "4NPg-YUxB6gC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Цель:** собрать удобный датафрейм, где в каждой строке есть все тексты и метаданные пары.\n",
        "\n",
        "Идея в том, чтобы из `train` и `items` получить таблицу, где в каждой строке:\n",
        "\n",
        "- идентификаторы пары и целевой класс,\n",
        "- тексты и/или заголовки левого и правого постов,\n",
        "- при желании - другие поля.\n",
        "\n",
        "Аналогично для `test`.\n",
        "\n",
        "Конкретные имена колонок и то, как именно вы склеиваете тексты - на ваше усмотрение. Важно, чтобы в дальнейшем вам было удобно из этого строить признаки для модели."
      ],
      "metadata": {
        "id": "WE0P2k2DCE6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge train_pairs_raw и test_pairs_raw с items\n",
        "# your code here ヾ(๑╹◡╹)ﾉ"
      ],
      "metadata": {
        "id": "yzhyt7tsCPr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Задание 3. Базовый текстовый baseline (3 балла)"
      ],
      "metadata": {
        "id": "GJcpLkZICY4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Цель:** построить простой, но полноценный pipeline для задачи:\n",
        "\n",
        "1. подготовка текстовых признаков для пары,\n",
        "2. обучение модели,\n",
        "3. оценка качества на валидации (Weighted F1),\n",
        "4. формирование корректного `submission.csv` для Kaggle.\n",
        "\n",
        "Здесь должна появиться первая рабочая модель, которая:\n",
        "\n",
        "- использует текст пары в каком-то разумном виде,\n",
        "- обучается на train,\n",
        "- даёт осмысленное качество на валидации,\n",
        "- позволяет сформировать `submission.csv` для Kaggle.\n",
        "\n",
        "**Схема (это только логика, а не пошаговая инструкция):**\n",
        "\n",
        "1. Как-то представить текст пары.\n",
        "\n",
        "   Начать проще всего с заголовков, а там можно и тексты добавить.\n",
        "\n",
        "2. Сделать разбиение на train/validation:\n",
        "   - выделить часть train-пар под валидацию;\n",
        "   - желательно учитывать классы (`stratify` по `result`), но это не жёсткое требование.\n",
        "\n",
        "3. Выбрать способ векторизации текста.\n",
        "   Стартануть с чего-то базового:\n",
        "   - Bag-of-Words,\n",
        "   - TF-IDF с униграммами/биграммами.\n",
        "\n",
        "4. Обучить базовую модель. Например:\n",
        "   - логистическая регрессия,\n",
        "   - линейный SVM,\n",
        "   - SGD-классификатор.\n",
        "\n",
        "5. Посчитать качество на валидации.\n",
        "   - Weighted F1 (главная метрика),\n",
        "   - короткий комментарий, какие классы предсказываются лучше/хуже.\n",
        "\n",
        "6. Сделать baseline-сабмит.  \n",
        "   - обучить выбранную модель на всём train,\n",
        "   - применить её к test-парам,\n",
        "   - сохранить `submission.csv` с колонками `pairId,result`.\n",
        "\n",
        "Конкретный выбор векторизатора/модели - на вашей совести, но важно, чтобы это был действительно работающий конец-до-конца baseline, а не только эксперименты."
      ],
      "metadata": {
        "id": "a7DTJ60KCkHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# базовый текстовый pipeline\n",
        "# your code here (づ｡◕‿‿◕｡)づ"
      ],
      "metadata": {
        "id": "kZF63rPoF1F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Улучшения baseline'а (дополнительные баллы)"
      ],
      "metadata": {
        "id": "Mh6okW-4HZBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше начинается про \"улучшение и осмысленность\". Здесь вы можете получить дополнительные баллы за продуманные эксперименты."
      ],
      "metadata": {
        "id": "ncZHFIITHOZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Углублённый EDA по текстам (чтобы понимать, какие фичи вообще нужны)\n",
        "\n",
        "Перед тем как изобретать признаки, полезно чуть глубже посмотреть на тексты. Возможные направления:\n",
        "\n",
        "- распределения длины:\n",
        "  - заголовков,\n",
        "  - текстов,\n",
        "  - объединённых текстов;\n",
        "- сравнение этих распределений по классам;\n",
        "- частотные слова/фразы для разных классов:\n",
        "  - какие токены чаще встречаются в `relevant_plus`,\n",
        "  - какие - в `no_relevant`;\n",
        "- проверка доли пар с одинаковыми авторами в разных классах;\n",
        "- среднее/типичное количество общих слов между текстами пары по каждому классу.\n",
        "\n",
        "Не нужно превращать это в отдельный научный отчёт,  \n",
        "но 2–3 осмысленных наблюдения, которые потом перейдут в фичи, - это очень хорошо."
      ],
      "metadata": {
        "id": "n5_ZYn1oHmwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# углублённый EDA\n",
        "# your code here ┌(ಠ_ಠ)┘"
      ],
      "metadata": {
        "id": "JrNcv9Q2H6yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2. Улучшения моделей и признаков\n",
        "\n",
        "Нужно реализовать минимум два осмысленных улучшения относительно baseline.  \n",
        "Это могут быть:\n",
        "\n",
        "- Более выразительные текстовые представления:\n",
        "  - n-граммы большей длины,\n",
        "  - раздельные векторы для левой и правой части с последующей склейкой,\n",
        "  - эмбеддинги предложений (Sentence-BERT, RuBERT и т.п.).\n",
        "\n",
        "- Ручные фичи, вдохновлённые EDA:\n",
        "  - длины текстов, разницы длин,\n",
        "  - доля общих слов,\n",
        "  - индикаторы вроде совпадения авторов,\n",
        "  - другие простые числовые признаки.\n",
        "\n",
        "- NER (Named Entity Recognition) - особенно приветствуется:\n",
        "  - извлечь сущности из текстов,\n",
        "  - посчитать пересечение по сущностям для пары,\n",
        "  - добавить это как признаки и посмотреть, влияет ли на F1.\n",
        "\n",
        "- Трансформеры (по желанию):\n",
        "  - BERT / другая модель как cross-encoder для пары текстов,\n",
        "  - сравнение \"только заголовки\" vs \"заголовки + тексты\",\n",
        "  - обсуждение влияния длины контекста.\n",
        "\n",
        "Важно: здесь нет цели перебрать всё подряд. Нам интересно увидеть, что вы:\n",
        "- опираетесь на EDA при выборе фич,\n",
        "- пробуете хотя бы пару разных направлений,\n",
        "- сравниваете их по той же самой валидации, что и baseline.\n",
        "\n",
        ">\n"
      ],
      "metadata": {
        "id": "3YX57zF6HlNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# эксперименты с улучшенными признаками / моделями\n",
        "# your code here ٩(⁎❛ᴗ❛⁎)۶"
      ],
      "metadata": {
        "id": "pYBaCibOHRHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Таблица экспериментов и выводы"
      ],
      "metadata": {
        "id": "mfoYgbIRDB45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В конце экспериментов полезно аккуратно собрать результаты.\n",
        "\n",
        "Рекомендуется:\n",
        "\n",
        "1. Выбрать несколько конфигураций (baseline + улучшения, 3–5 вариантов).\n",
        "2. Для каждой записать:\n",
        "   - краткое описание (какие фичи и модель),\n",
        "   - Weighted F1 на валидации.\n",
        "3. Оформить это в виде таблицы (пример):\n",
        "\n",
        "| Модель / фичи                     | Weighted F1 (val) |\n",
        "|-----------------------------------|-------------------|\n",
        "| метод 1     | 0.XX              |\n",
        "| метод 2          | 0.XX              |\n",
        "| метод 3    | 0.XX              |\n",
        "| метод 4    | 0.XX              |\n",
        "| метод 5 | 0.XX              |"
      ],
      "metadata": {
        "id": "UU4JLHX8C5ks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Воспроизводимый пайплайн (обязательный блок, если вы участовали в соревновании)"
      ],
      "metadata": {
        "id": "-fV6fHbe8wrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом разделе добавьте, пожалуйста, одну аккуратную кодовую ячейку, в которой собран **целостный пайплайн** для получения финального `submission.csv`.\n",
        "\n",
        "Эта ячейка должна:\n",
        "\n",
        "1. Загрузить данные\n",
        "   - либо повторно считать `items.parquet`, `train.csv`, `test.csv`,  \n",
        "   - либо опираться на уже загруженные выше переменные (но без ручного редактирования кода).\n",
        "\n",
        "2. Подготовить признаки\n",
        "   - собрать тексты пар в том виде, в котором они используются вашей финальной моделью;  \n",
        "   - при необходимости - достроить дополнительные фичи.\n",
        "\n",
        "3. Создать и загрузить финальную модель\n",
        "   - либо обучить её (если обучение занимает разумное время в Colab/Kaggle),  \n",
        "   - либо загрузить заранее обученные веса:\n",
        "     - из локального файла,\n",
        "     - или по ссылке (Google Drive / Kaggle Datasets и т.д.).\n",
        "\n",
        "4. Выполнить инференс на test\n",
        "   - получить предсказания классов для всех строк `test.csv`.\n",
        "\n",
        "5. Сформировать `submission.csv` в формате соревнования:\n",
        "   - две колонки: `pairId`, `result`,\n",
        "   - `pairId` - как в исходном `test.csv`,\n",
        "   - `result` - одна из 4 меток: `relevant_plus`, `relevant`, `relevant_minus`, `no_relevant`.\n",
        "\n",
        "**Требование:**  \n",
        "\n",
        "если ассистент запустит только эту ячейку (при условии, что все необходимые функции/классы определены выше), на выходе должен появиться корректный `submission.csv`, соответствующий вашему финальному сабмиту на Kaggle.\n",
        "\n",
        "Если ваша финальная модель обучалась долго (например, трансформер):\n",
        "\n",
        "- обучите её один раз заранее;\n",
        "- сохраните веса в файл и выложите в доступное место;\n",
        "- в этой ячейке загрузите готовые веса, а не переобучайте модель с нуля;\n",
        "- кратко укажите в комментарии, откуда берутся веса (ссылка/путь)."
      ],
      "metadata": {
        "id": "ik4YkZcV87EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Воспроизводимый пайплайн: формирование финального submission.csv\n",
        "# TODO: заполните эту ячейку так, чтобы при запуске она:\n",
        "#  1) подготовила данные и признаки\n",
        "#  2) загрузила/создала вашу финальную модель\n",
        "#  3) посчитала предсказания на test\n",
        "#  4) сохранила submission.csv в нужном формате\n",
        "\n",
        "# your code here (⌐■_■)"
      ],
      "metadata": {
        "id": "rQQKLyXq8r_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Завершающий блок: выводы\n",
        "\n",
        "Пожалуйста, в конце ноутбука добавьте небольшой текстовый вывод (5–10 предложений). Можно ориентироваться на такой план:\n",
        "\n",
        "- Какой baseline вы построили и какую метрику он давал?\n",
        "- Какие улучшения вы попробовали (эмбеддинги, NER, пересечения и т.п.)?\n",
        "- Что реально помогло улучшить качество, а что - нет (и почему, по вашему мнению)?\n",
        "- Какой итоговый Weighted F1 на валидации у вашей лучшей модели?\n",
        "- Короткий комментарий о результате на Kaggle.\n",
        "\n",
        "Ответ: # your text here (ಠ.ಠ)"
      ],
      "metadata": {
        "id": "P6rnf-QM1lwg"
      }
    }
  ]
}
