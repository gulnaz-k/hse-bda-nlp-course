{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC0u3yAWvB3P"
   },
   "source": [
    "# –°–µ–º–∏–Ω–∞—Ä 4. Sequence Labeling (POS + NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIHMQ4vLX6Ni"
   },
   "source": [
    "## –í–≤–µ–¥–µ–Ω–∏–µ: –ß—Ç–æ —Ç–∞–∫–æ–µ Token Classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu2av8utvMVg"
   },
   "source": [
    "–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Å –∫–ª–∞—Å—Å–æ–º –∑–∞–¥–∞—á Sequence Labeling (—Ä–∞–∑–º–µ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏). –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ (Text Classification), –∑–¥–µ—Å—å –º—ã –ø—Ä–∏–Ω–∏–º–∞–µ–º —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ.\n",
    "\n",
    "–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏:\n",
    "\n",
    "1.  POS (Part-of-Speech tagging). –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∞—Å—Ç–∏ —Ä–µ—á–∏.\n",
    "      * *–ü—Ä–∏–º–µ—Ä:* `–ú–∞–º–∞ (NOUN) –º—ã–ª–∞ (VERB) —Ä–∞–º—É (NOUN)`.\n",
    "2.  NER (Named Entity Recognition). –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π.\n",
    "      * *–ü—Ä–∏–º–µ—Ä:* `–ò–ª–æ–Ω (B-PER) –ú–∞—Å–∫ (I-PER) –∫—É–ø–∏–ª (O) Twitter (B-ORG)`.\n",
    "\n",
    "**–§–æ—Ä–º–∞—Ç—ã —Ä–∞–∑–º–µ—Ç–∫–∏ (BIO / BIOES)**\n",
    "\n",
    "–ß—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–ª–∞, –≥–¥–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∏ –≥–¥–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Å—É—â–Ω–æ—Å—Ç—å (–æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ –æ–Ω–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–≤, –∫–∞–∫ \"New York\"), –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—Ö–µ–º—ã —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
    "\n",
    "  * **B-** (Begin): –Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏.\n",
    "  * **I-** (Inside): –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏.\n",
    "  * **O** (Outside): —Ç–æ–∫–µ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å—É—â–Ω–æ—Å—Ç—å—é.\n",
    "  * *(–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* **E-** (End) –∏ **S-** (Single): –∫–æ–Ω–µ—Ü –∏ –æ–¥–∏–Ω–æ—á–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd-WfMjaYMd2"
   },
   "source": [
    "**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–æ—É—Ç–±—É–∫–∞**\n",
    "\n",
    "1. –ß–∞—Å—Ç—å A - \"–ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤–æ–µ\": –¥–µ–ª–∞–µ–º inference POS+NER –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∏ —Ä—É—Å—Å–∫–æ–≥–æ, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ —Ñ–æ—Ä–º–∞—Ç—ã –≤—ã–≤–æ–¥–∞.\n",
    "2. –ß–∞—Å—Ç—å B - \"Best practice fine-tuning\": –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ HuggingFace ü§ó Transformers –ø–æ–¥ token classification (NER/POS), –æ–±—Å—É–∂–¥–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Ä–∞–∑–º–µ—Ç–∫—É BIO/BIOES –∏ –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞.\n",
    "\n",
    "–ü–æ —Ö–æ–¥—É –±—É–¥–µ–º –æ–±—Ä–∞—â–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ –≤ sequence labeling –º–µ—Ç–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤ —Å–≤—è–∑–∞–Ω—ã –º–µ–∂–¥—É —Å–æ–±–æ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, I-PER –Ω–µ –¥–æ–ª–∂–µ–Ω –ø–æ—è–≤–ª—è—Ç—å—Å—è –≤ –Ω–∏–∫—É–¥–∞), –∏ —á—Ç–æ NER –æ–±—ã—á–Ω–æ —É–¥–æ–±–Ω–µ–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ø–∞–Ω—ã —Å—É—â–Ω–æ—Å—Ç–µ–π, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –º–µ—Ç–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hQMwE2qYPGx"
   },
   "source": [
    "## –ß–∞—Å—Ç—å A. Stanza: –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFheRbpRYRte"
   },
   "source": [
    "–ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É [Stanza](https://stanfordnlp.github.io/stanza/) –æ—Ç Stanford NLP Group. –≠—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π Python-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –º–æ–¥–µ–ª–∏ (PyTorch) –ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn67P0koYUK7"
   },
   "source": [
    "### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bADaAP7zYWrN"
   },
   "outputs": [],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxtwJ-FvYYoH"
   },
   "source": [
    "–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏. Stanza —Ö—Ä–∞–Ω–∏—Ç –∏—Ö –ª–æ–∫–∞–ª—å–Ω–æ (–æ–±—ã—á–Ω–æ –≤ `~/stanza_resources`). `download` –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRVNOpVWXISZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import stanza\n",
    "\n",
    "RES_DIR = Path(\"/content/stanza_resources\")\n",
    "RES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"STANZA_RESOURCES_DIR\"] = str(RES_DIR)\n",
    "\n",
    "stanza.download(\"en\", processors=\"tokenize,pos,lemma,ner\", model_dir=str(RES_DIR), verbose=True)\n",
    "stanza.download(\"ru\", processors=\"tokenize,pos,lemma,ner\", model_dir=str(RES_DIR), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVyJCzGzXKKL"
   },
   "outputs": [],
   "source": [
    "# Pipeline –∏—Å–ø–æ–ª—å–∑—É–µ—Ç dir (–Ω–µ model_dir!)\n",
    "nlp_en = stanza.Pipeline(\"en\", processors=\"tokenize,pos,lemma,ner\", dir=str(RES_DIR), use_gpu=False)\n",
    "nlp_ru = stanza.Pipeline(\"ru\", processors=\"tokenize,pos,lemma,ner\", dir=str(RES_DIR), use_gpu=False)\n",
    "\n",
    "doc_en = nlp_en(\"Barack Obama was born in Hawaii.\")\n",
    "doc_ru = nlp_ru(\"–ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤ –ø—Ä–∏–µ—Ö–∞–ª –≤ –ú–æ—Å–∫–≤—É.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xA-chCMHXcly",
    "outputId": "f736fe51-8500-4da7-9a18-790544b448eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN ents: [('Barack Obama', 'PERSON'), ('Hawaii', 'GPE')]\n",
      "RU ents: [('–ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤', 'PER'), ('–ú–æ—Å–∫–≤—É', 'LOC')]\n"
     ]
    }
   ],
   "source": [
    "print(\"EN ents:\", [(e.text, e.type) for e in doc_en.ents])\n",
    "print(\"RU ents:\", [(e.text, e.type) for e in doc_ru.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtyq_f5WYfUw"
   },
   "source": [
    "### –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LVUGv9gYhef"
   },
   "source": [
    "–í Stanza –≤—Å—è —Ä–∞–±–æ—Ç–∞ —Å—Ç—Ä–æ–∏—Ç—Å—è —á–µ—Ä–µ–∑ –æ–±—ä–µ–∫—Ç `Pipeline`. –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º—ã —É–∫–∞–∑—ã–≤–∞–µ–º:\n",
    "\n",
    "1.  **–Ø–∑—ã–∫** (`lang`).\n",
    "2.  **–°–ø–∏—Å–æ–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤** (`processors`): –∫–∞–∫–∏–µ –∑–∞–¥–∞—á–∏ —Ä–µ—à–∞—Ç—å.\n",
    "      * `tokenize`: —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ —Ç–æ–∫–µ–Ω—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).\n",
    "      * `mwt`: Multi-Word Token expansion (–∞–∫—Ç—É–∞–ª—å–Ω–æ –¥–ª—è —Ñ—Ä., –Ω–µ–º., —É–∫—Ä. —è–∑—ã–∫–æ–≤).\n",
    "      * `pos`: —á–∞—Å—Ç–∏ —Ä–µ—á–∏.\n",
    "      * `lemma`: –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (–Ω–∞—á–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ —Å–ª–æ–≤–∞).\n",
    "      * `ner`: –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "> –í–∞–∂–Ω–æ: Pipeline –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—ã—Ç–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU. –ï—Å–ª–∏ GPU –Ω–µ—Ç, –æ–Ω –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è –Ω–∞ CPU, –Ω–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–ª–µ–Ω–Ω–µ–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPR9VKUhYmoy"
   },
   "outputs": [],
   "source": [
    "# —Å–æ–∑–¥–∞–µ–º Pipeline –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞\n",
    "# –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞–º–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "nlp_en = stanza.Pipeline(\n",
    "    lang=\"en\",\n",
    "    processors=\"tokenize,pos,lemma,ner\",\n",
    "    verbose=False,\n",
    "    use_gpu=True # —Å—Ç–∞–≤–∏–º False, –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å CUDA\n",
    ")\n",
    "\n",
    "text_en = \"Steve Jobs presented the first iPhone in San Francisco in 2007.\"\n",
    "\n",
    "# –∑–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
    "doc_en = nlp_en(text_en)\n",
    "doc_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_P3Kl0-Y4OU"
   },
   "source": [
    "### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: Document, Sentence, Token, Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4d4XerrY7en"
   },
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã - –æ–±—ä–µ–∫—Ç `Document`. –î–∞–≤–∞–π—Ç–µ –∑–∞–≥–ª—è–Ω–µ–º –≤–Ω—É—Ç—Ä—å, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø—Ä–µ–≤—Ä–∞—â–∞—Ç—å –µ–≥–æ –≤ —Ç–∞–±–ª–∏—Ü—É.\n",
    "–ò–µ—Ä–∞—Ä—Ö–∏—è Stanza: `Document` -\\> —Å–ø–∏—Å–æ–∫ `Sentence` -\\> —Å–ø–∏—Å–æ–∫ `Token` -\\> —Å–ø–∏—Å–æ–∫ `Word`.\n",
    "\n",
    "> Token vs Word. –í –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –æ–Ω–∏ —á–∞—Å—Ç–æ —Å–æ–≤–ø–∞–¥–∞—é—Ç (1 –∫ 1). –ù–æ –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —è–∑—ã–∫–∞—Ö –æ–¥–∏–Ω \"Token\" (–ø–æ–¥—Å—Ç—Ä–æ–∫–∞) –º–æ–∂–µ—Ç –Ω–µ—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏—Ö \"Words\".\n",
    ">\n",
    ">   * POS –∏ Lemma - —Å–≤–æ–π—Å—Ç–≤–∞ **Word**.\n",
    ">   * NER - —Å–≤–æ–π—Å—Ç–≤–æ **Token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2wOcCndZGDa",
    "outputId": "17ce18c2-dfeb-4908-902e-f3103c321957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: Steve Jobs presented the first iPhone in San Francisco in 2007.\n",
      "\n",
      "TOKEN           NER (Token)     POS (Word) LEMMA (Word)   \n",
      "------------------------------------------------------------\n",
      "Steve           B-PERSON        PROPN      Steve          \n",
      "Jobs            E-PERSON        PROPN      Jobs           \n",
      "presented       O               VERB       present        \n",
      "the             O               DET        the            \n",
      "first           S-ORDINAL       ADJ        first          \n",
      "iPhone          S-PRODUCT       PROPN      iPhone         \n",
      "in              O               ADP        in             \n",
      "San             B-GPE           PROPN      San            \n",
      "Francisco       E-GPE           PROPN      Francisco      \n",
      "in              O               ADP        in             \n",
      "2007            S-DATE          NUM        2007           \n",
      ".               O               PUNCT      .              \n"
     ]
    }
   ],
   "source": [
    "# –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ\n",
    "sent = doc_en.sentences[0]\n",
    "\n",
    "print(f\"–¢–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {sent.text}\\n\")\n",
    "\n",
    "print(f\"{'TOKEN':<15} {'NER (Token)':<15} {'POS (Word)':<10} {'LEMMA (Word)':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for token in sent.tokens:\n",
    "    # NER —Ç–µ–≥ –∂–∏–≤–µ—Ç –≤ —Ç–æ–∫–µ–Ω–µ\n",
    "    ner_tag = token.ner\n",
    "\n",
    "    # –≤ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –æ–±—ã—á–Ω–æ 1 —Ç–æ–∫–µ–Ω = 1 —Å–ª–æ–≤–æ\n",
    "    word = token.words[0]\n",
    "\n",
    "    print(f\"{token.text:<15} {ner_tag:<15} {word.upos:<10} {word.lemma:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gREh-MM7ZLT4"
   },
   "source": [
    "### –ê–Ω–∞–ª–∏–∑ –≤ Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hgkn42kVZNJs"
   },
   "source": [
    "–î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–ø—Ä—è–º–ª—è–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é Stanza –≤ –ø–ª–æ—Å–∫—É—é —Ç–∞–±–ª–∏—Ü—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "kaeSAEuXZQbc",
    "outputId": "bd02b298-7611-458e-d681-24f7ee3e847f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_en\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"sent_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"iPhone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"iPhone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemma\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"iPhone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upos\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"PROPN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xpos\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"NNP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feats\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_bio\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"E-PERSON\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 0,\n        \"max\": 62,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 5,\n        \"max\": 63,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_en"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-a2848d21-4c77-4d92-ad1f-3015189fb36d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>feats</th>\n",
       "      <th>ner_bio</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Steve</td>\n",
       "      <td>Steve</td>\n",
       "      <td>Steve</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>B-PERSON</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>Jobs</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>E-PERSON</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>presented</td>\n",
       "      <td>presented</td>\n",
       "      <td>present</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBD</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...</td>\n",
       "      <td>O</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>O</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "      <td>first</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Degree=Pos|NumForm=Word|NumType=Ord</td>\n",
       "      <td>S-ORDINAL</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>S-PRODUCT</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>San</td>\n",
       "      <td>San</td>\n",
       "      <td>San</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>B-GPE</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>E-GPE</td>\n",
       "      <td>45</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>None</td>\n",
       "      <td>O</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2848d21-4c77-4d92-ad1f-3015189fb36d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-a2848d21-4c77-4d92-ad1f-3015189fb36d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-a2848d21-4c77-4d92-ad1f-3015189fb36d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-390c1577-1eb8-42a2-a421-d69c43d65b76\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-390c1577-1eb8-42a2-a421-d69c43d65b76')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-390c1577-1eb8-42a2-a421-d69c43d65b76 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   sent_id      token       word      lemma   upos xpos  \\\n",
       "0        1      Steve      Steve      Steve  PROPN  NNP   \n",
       "1        1       Jobs       Jobs       Jobs  PROPN  NNP   \n",
       "2        1  presented  presented    present   VERB  VBD   \n",
       "3        1        the        the        the    DET   DT   \n",
       "4        1      first      first      first    ADJ   JJ   \n",
       "5        1     iPhone     iPhone     iPhone  PROPN  NNP   \n",
       "6        1         in         in         in    ADP   IN   \n",
       "7        1        San        San        San  PROPN  NNP   \n",
       "8        1  Francisco  Francisco  Francisco  PROPN  NNP   \n",
       "9        1         in         in         in    ADP   IN   \n",
       "\n",
       "                                               feats    ner_bio  start  end  \n",
       "0                                        Number=Sing   B-PERSON      0    5  \n",
       "1                                        Number=Sing   E-PERSON      6   10  \n",
       "2  Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbF...          O     11   20  \n",
       "3                          Definite=Def|PronType=Art          O     21   24  \n",
       "4                Degree=Pos|NumForm=Word|NumType=Ord  S-ORDINAL     25   30  \n",
       "5                                        Number=Sing  S-PRODUCT     31   37  \n",
       "6                                               None          O     38   40  \n",
       "7                                        Number=Sing      B-GPE     41   44  \n",
       "8                                        Number=Sing      E-GPE     45   54  \n",
       "9                                               None          O     55   57  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doc_to_df(doc):\n",
    "    \"\"\"\n",
    "    –°–æ–±–∏—Ä–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —É—Ä–æ–≤–Ω–µ–π Token –∏ Word –≤ –µ–¥–∏–Ω—ã–π DataFrame.\n",
    "    –í–∞–∂–Ω–æ: NER-—Ç–µ–≥–∏ –±–µ—Ä–µ–º –∏–∑ Token, –∞ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É (POS, Lemma) –∏–∑ Word.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sent_id, sent in enumerate(doc.sentences, start=1):\n",
    "        for tok in sent.tokens:\n",
    "            # NER-—Ç–µ–≥ (BIOES) –ø—Ä–∏–≤—è–∑–∞–Ω –∫ —Ç–æ–∫–µ–Ω—É\n",
    "            tok_ner = getattr(tok, \"ner\", \"O\")\n",
    "\n",
    "            for w in tok.words:\n",
    "                rows.append({\n",
    "                    \"sent_id\": sent_id,\n",
    "                    \"token\": tok.text,\n",
    "                    \"word\": w.text,\n",
    "                    \"lemma\": w.lemma,\n",
    "                    \"upos\": w.upos, # universal POS tags\n",
    "                    \"xpos\": w.xpos, # treebank-specific tags\n",
    "                    \"feats\": w.feats, # –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "                    \"ner_bio\": tok_ner, # –±–∏–æ-—Ç–µ–≥ —Ç–æ–∫–µ–Ω–∞\n",
    "                    \"start\": tok.start_char,\n",
    "                    \"end\": tok.end_char\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_en = doc_to_df(doc_en)\n",
    "df_en.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jUquUd9ZZAE"
   },
   "source": [
    "### –†–∞–±–æ—Ç–∞ —Å —Å—É—â–Ω–æ—Å—Ç—è–º–∏ (Spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DAOi6kgZbYL"
   },
   "source": [
    "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å `ner_bio` (—Ç–µ–≥–∏ B-PERSON, E-PERSON) –≥–ª–∞–∑–∞–º–∏ –Ω–µ—É–¥–æ–±–Ω–æ. Stanza –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–ª–µ–∏–≤–∞–µ—Ç —Ç–µ–≥–∏ –≤ –≥–æ—Ç–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã-—Å—É—â–Ω–æ—Å—Ç–∏ `doc.ents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkizW7xmZeOo",
    "outputId": "81b667d8-e62a-4ef0-c474-e0da818f0be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTITY               TYPE       RANGE\n",
      "----------------------------------------\n",
      "Steve Jobs           PERSON     [0, 10]\n",
      "first                ORDINAL    [25, 30]\n",
      "iPhone               PRODUCT    [31, 37]\n",
      "San Francisco        GPE        [41, 54]\n",
      "2007                 DATE       [58, 62]\n"
     ]
    }
   ],
   "source": [
    "def print_ents(doc):\n",
    "    if not doc.ents:\n",
    "        print(\"–°—É—â–Ω–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\")\n",
    "        return\n",
    "\n",
    "    print(f\"{'ENTITY':<20} {'TYPE':<10} {'RANGE'}\")\n",
    "    print(\"-\" * 40)\n",
    "    for ent in doc.ents:\n",
    "        # ent - —ç—Ç–æ Span, —É –Ω–µ–≥–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, —Ç–∏–ø –∏ –ø–æ–∑–∏—Ü–∏–∏\n",
    "        print(f\"{ent.text:<20} {ent.type:<10} [{ent.start_char}, {ent.end_char}]\")\n",
    "\n",
    "print_ents(doc_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLUkksL0ZkZE"
   },
   "source": [
    "### –†—É—Å—Å–∫–∏–π —è–∑—ã–∫ (Stanza RU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH9WcygrZoLs"
   },
   "source": [
    "–ü—Ä–∏–º–µ–Ω–∏–º —Ç–æ—Ç –∂–µ –ø–æ–¥—Ö–æ–¥ –∫ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É. Stanza –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ –∫–æ—Ä–ø—É—Å–µ —Å **WikiNER**, –ø–æ—ç—Ç–æ–º—É –Ω–∞–±–æ—Ä —Ç–µ–≥–æ–≤ –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6RzKr5zZqFg"
   },
   "outputs": [],
   "source": [
    "nlp_ru = stanza.Pipeline(\n",
    "    \"ru\",\n",
    "    processors=\"tokenize,pos,lemma,ner\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "text_ru = \"–ê–ª—å–±–µ—Ä—Ç –≠–π–Ω—à—Ç–µ–π–Ω —Ä–æ–¥–∏–ª—Å—è –≤ –£–ª—å–º–µ –∏ —Ä–∞–±–æ—Ç–∞–ª –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏. –í 1921 –≥–æ–¥—É –æ–Ω –ø–æ–ª—É—á–∏–ª –ù–æ–±–µ–ª–µ–≤—Å–∫—É—é –ø—Ä–µ–º–∏—é –ø–æ —Ñ–∏–∑–∏–∫–µ.\"\n",
    "doc_ru = nlp_ru(text_ru)\n",
    "\n",
    "# –≤—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É\n",
    "df_ru = doc_to_df(doc_ru)\n",
    "display(df_ru.head(15)) # display —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –Ω–æ—É—Ç–±—É–∫–∞—Ö –∫—Ä–∞—Å–∏–≤–µ–µ print\n",
    "\n",
    "print(\"\\n –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ \")\n",
    "print_ents(doc_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KthdaucSZvzc"
   },
   "source": [
    "### (Advanced) Stanza Client –¥–ª—è Stanford CoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu8JXUy9Z0_U"
   },
   "source": [
    "Stanza - —ç—Ç–æ –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–µ–π—Ä–æ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω, –Ω–æ –∏ **Python-–∫–ª–∏–µ–Ω—Ç** –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ Java-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Stanford CoreNLP.\n",
    "CoreNLP —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ —Å–µ—Ä–≤–µ—Ä. –≠—Ç–æ –ø–æ–ª–µ–∑–Ω–æ, –µ—Å–ª–∏ –≤–∞–º –Ω—É–∂–Ω—ã —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–∫–∞ –Ω–µ—Ç –≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ Stanza (–Ω–∞–ø—Ä–∏–º–µ—Ä, Coreference Resolution –∏–ª–∏ OpenIE), –∏–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–µ, –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ Java-–º–æ–¥–µ–ª–∏.\n",
    "\n",
    "**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**\n",
    "\n",
    "  * –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–∞—è Java.\n",
    "  * –°–∫–∞—á–∞–Ω–Ω—ã–π CoreNLP (–¥–µ–ª–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ Stanza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHvqQy1JZ5S-",
    "outputId": "99c58294-9f94-4bb5-fc9b-29d2baf8593e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CoreNLP Server...\n",
      "\n",
      "--- CoreNLP Result ---\n",
      "Albert          NNP   PERSON\n",
      "Einstein        NNP   PERSON\n",
      "was             VBD   O\n",
      "a               DT    O\n",
      "German          JJ    NATIONALITY\n",
      "-               HYPH  O\n",
      "born            VBN   O\n",
      "theoretical     JJ    TITLE\n",
      "physicist       NN    TITLE\n",
      ".               .     O\n",
      "Server stopped.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stanza.server import CoreNLPClient\n",
    "\n",
    "# c–∫–∞—á–∏–≤–∞–µ–º Java-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ CoreNLP –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É\n",
    "corenlp_dir = \"./corenlp\"\n",
    "# –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑\n",
    "if not os.path.exists(corenlp_dir):\n",
    "    print(\"Downloading CoreNLP...\")\n",
    "    stanza.install_corenlp(dir=corenlp_dir)\n",
    "\n",
    "os.environ[\"CORENLP_HOME\"] = corenlp_dir\n",
    "\n",
    "# –∑–∞–ø—É—Å–∫–∞–µ–º –∫–ª–∏–µ–Ω—Ç —á–µ—Ä–µ–∑ Context Manager (with)\n",
    "# Best Practice: —Å–µ—Ä–≤–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ –±–ª–æ–∫–∞ with\n",
    "print(\"Starting CoreNLP Server...\")\n",
    "\n",
    "with CoreNLPClient(\n",
    "    annotators=['tokenize', 'ssplit', 'pos', 'lemma', 'ner'],\n",
    "    memory='4G',\n",
    "    endpoint='http://localhost:9001', # –ø–æ—Ä—Ç 9000 —á–∞—Å—Ç–æ –∑–∞–Ω—è—Ç –≤ Colab\n",
    "    be_quiet=True\n",
    ") as client:\n",
    "\n",
    "    text = \"Albert Einstein was a German-born theoretical physicist.\"\n",
    "\n",
    "    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–µ—Ä–≤–µ—Ä\n",
    "    ann = client.annotate(text)\n",
    "\n",
    "    # –æ–±—ä–µ–∫—Ç ann ‚Äî —ç—Ç–æ Protobuf –æ–±—ä–µ–∫—Ç, –Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Ö–æ–∂–∞\n",
    "    print(\"\\n--- CoreNLP Result ---\")\n",
    "    for sent in ann.sentence:\n",
    "        for token in sent.token:\n",
    "            print(f\"{token.word:<15} {token.pos:<5} {token.ner}\")\n",
    "\n",
    "print(\"Server stopped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7S4OsjBfbaTP"
   },
   "source": [
    "## –ß–∞—Å—Ç—å B. Fine-tuning –º–æ–¥–µ–ª–∏ –¥–ª—è Token Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE_X_c5ecYva"
   },
   "source": [
    "–í —ç—Ç–æ–π —á–∞—Å—Ç–∏ —Å–µ–º–∏–Ω–∞—Ä–∞ –º—ã –Ω–∞—É—á–∏–º—Å—è –¥–æ–æ–±—É—á–∞—Ç—å (fine-tune) –º–æ–¥–µ–ª—å –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [ü§ó Transformers](https://github.com/huggingface/transformers) –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3feJsl-9cch5"
   },
   "source": [
    "### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zepBAFXCdv07"
   },
   "source": [
    "–ï—Å–ª–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ –≤ Colab, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏. –ù–∞–º —Ç–∞–∫–∂–µ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è `seqeval` –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KYZIRjDuER7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Xet - –º–µ—Ö–∞–Ω–∏–∑–º —É—Å–∫–æ—Ä–µ–Ω–Ω–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ —Å HuggingFace Hub\n",
    "# High performance mode –ø–æ–º–æ–≥–∞–µ—Ç –±—ã—Å—Ç—Ä–µ–µ –∫–∞—á–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã –º–æ–¥–µ–ª–µ–π\n",
    "os.environ[\"HF_XET_HIGH_PERFORMANCE\"] = \"1\"\n",
    "\n",
    "# —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã, —á—Ç–æ–±—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ –æ–±—Ä—ã–≤–∞–ª–æ—Å—å –ø—Ä–∏ –ø–ª–æ—Ö–æ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ\n",
    "os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"600\"\n",
    "os.environ[\"HF_HUB_ETAG_TIMEOUT\"] = \"60\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opD0aS18LYbD"
   },
   "outputs": [],
   "source": [
    "# transformers - —Å–∞–º–∏ –º–æ–¥–µ–ª–∏\n",
    "# datasets - –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "# seqeval - –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è NER\n",
    "# accelerate - –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è (–Ω—É–∂–µ–Ω –¥–ª—è Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yopJZ36Idszm"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets seqeval evaluate accelerate huggingface_hub hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxBlwrkhd3i9",
    "outputId": "a7d430bf-e2db-4cd8-f9f4-2c86ed252548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zES49vWgd8nW"
   },
   "source": [
    "–ó–∞–¥–∞–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã. –í—ã –º–æ–∂–µ—Ç–µ –ø–æ–º–µ–Ω—è—Ç—å `task` –Ω–∞ \"pos\" –∏–ª–∏ \"chunk\", –∏ –≤–µ—Å—å –Ω–æ—É—Ç–±—É–∫ –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ–¥ —ç—Ç—É –∑–∞–¥–∞—á—É.\n",
    "`batch_size` –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å, –µ—Å–ª–∏ —É –≤–∞—Å –º–∞–ª–æ –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1w3tg_3eASH"
   },
   "outputs": [],
   "source": [
    "task = \"ner\" # –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å \"ner\", \"pos\" –∏–ª–∏ \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\" # –ª–µ–≥–∫–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å (Distilled BERT)\n",
    "batch_size = 16 # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –∑–∞ —Ä–∞–∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kywVQY8deCH-"
   },
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxrpPFFTeEim"
   },
   "source": [
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É [ü§ó Datasets](https://github.com/huggingface/datasets) –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç—Ä–∏–∫.\n",
    "–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –¥–∞—Ç–∞—Å–µ—Ç **CoNLL-2003**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD_7hJ_2L1Zw"
   },
   "source": [
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –±–µ–Ω—á–º–∞—Ä–∫ **CoNLL-2003**.\n",
    "\n",
    "> **–°–ø—Ä–∞–≤–∫–∞ –æ –¥–∞—Ç–∞—Å–µ—Ç–µ:**\n",
    "> CoNLL-2003 —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π Reuters. –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–º–µ—á–µ–Ω—ã –≤—Ä—É—á–Ω—É—é –¥–ª—è —Ç—Ä–µ—Ö –∑–∞–¥–∞—á.\n",
    "> –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ö–µ–º—É **BIO (Begin-Inside-Outside)**:\n",
    ">\n",
    ">   * **B-XXX**: –ù–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏ —Ç–∏–ø–∞ XXX.\n",
    ">   * **I-XXX**: –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ —Ç–∏–ø–∞ XXX.\n",
    ">   * **O**: –¢–æ–∫–µ–Ω –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç—å—é.\n",
    ">\n",
    "> **–¢–∏–ø—ã —Å—É—â–Ω–æ—Å—Ç–µ–π:**\n",
    ">\n",
    ">   * `PER`: Person (–õ—é–¥–∏)\n",
    ">   * `ORG`: Organization (–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏)\n",
    ">   * `LOC`: Location (–õ–æ–∫–∞—Ü–∏–∏)\n",
    ">   * `MISC`: Miscellaneous (–†–∞–∑–Ω–æ–µ - –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–æ–≤, —Å–æ–±—ã—Ç–∏–π –∏ —Ç.–¥.)\n",
    "\n",
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ `datasets`. –û–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∞–µ—Ç —Ñ–∞–π–ª—ã, —Ä–∞—Å–ø–∞–∫—É–µ—Ç –∏—Ö –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç Arrow (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø–æ –ø–∞–º—è—Ç–∏).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lKVRWoFeIak",
    "outputId": "8df62113-1956-4a2b-9605-0244438352a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "datasets = load_dataset(\"lhoestq/conll2003\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxE5n_EmL76T"
   },
   "source": [
    "–û–±—ä–µ–∫—Ç `datasets` - —ç—Ç–æ `DatasetDict`. –û–Ω –ø–æ—Ö–æ–∂ –Ω–∞ —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á–∏ - —ç—Ç–æ —Å–ø–ª–∏—Ç—ã –¥–∞–Ω–Ω—ã—Ö:\n",
    "\n",
    "  * `train`: –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n",
    "  * `validation`: –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –æ—Ü–µ–Ω–∫–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è.\n",
    "  * `test`: –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El3J8RRBeW7K"
   },
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä. –í –¥–∞–Ω–Ω—ã—Ö —É–∂–µ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω—ã (—Ç–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ —Å–ª–æ–≤–∞) –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º –º–µ—Ç–∫–∏ (labels) –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏ (NER, POS, Chunking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i56lQRnjeYQ-",
    "outputId": "0c7d7fd8-e4fe-448f-b6bf-32d5f00094b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_HRDjUqeanM"
   },
   "source": [
    "–ú–µ—Ç–∫–∏ —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –≤–∏–¥–µ ID (—Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª). –ß—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ –æ–Ω–∏ –∑–Ω–∞—á–∞—Ç, –æ–±—Ä–∞—Ç–∏–º—Å—è –∫ –∞—Ç—Ä–∏–±—É—Ç—É `features` –Ω–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3OTCELBecyx",
    "outputId": "2a16cd87-166e-4bbd-a9e5-4d4685c38e32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(Value('int64'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"].features[f\"{task}_tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3OEDS88efqM"
   },
   "source": [
    "–î–ª—è NER –º–µ—Ç–∫–∏:\n",
    "\n",
    "  * `0` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç `'O'` (Outside - –Ω–µ —Å—É—â–Ω–æ—Å—Ç—å).\n",
    "  * –û—Å—Ç–∞–ª—å–Ω—ã–µ 4 —Ç–∏–ø–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π (`PER`, `ORG`, `LOC`, `MISC`) –∏–º–µ—é—Ç –ø—Ä–µ—Ñ–∏–∫—Å—ã:\n",
    "      * `B-` (Begin) - –Ω–∞—á–∞–ª–æ —Å—É—â–Ω–æ—Å—Ç–∏.\n",
    "      * `I-` (Inside) - –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ü–æ–ª—É—á–∏–º —Å–ø–∏—Å–æ–∫ –ø–æ–Ω—è—Ç–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Ç–æ–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUQRF01pejV9",
    "outputId": "dba233dc-aca5-48aa-b5c2-47a4c795829e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_feat = datasets[\"train\"].features[f\"{task}_tags\"]  # \"ner_tags\"\n",
    "\n",
    "# Fallback, –µ—Å–ª–∏ –∏–º–µ–Ω–∞ –Ω–µ –ø—Ä–æ–ø–∏—Å–∞–Ω—ã –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–¥–ª—è CoNLL –æ–Ω–∏ –µ—Å—Ç—å)\n",
    "if hasattr(tags_feat, \"feature\") and hasattr(tags_feat.feature, \"names\"):\n",
    "    label_list = tags_feat.feature.names\n",
    "else:\n",
    "    label_list = [\"O\",\n",
    "                  \"B-PER\", \"I-PER\",\n",
    "                  \"B-ORG\", \"I-ORG\",\n",
    "                  \"B-LOC\", \"I-LOC\",\n",
    "                  \"B-MISC\",\"I-MISC\"]\n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXduPvd-MT7B"
   },
   "source": [
    "Sanity check (–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏). –ü—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫–∏–µ ID –º–µ—Ç–æ–∫ –≤–æ–æ–±—â–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –Ω–∞—á–∞–ª–µ –¥–∞—Ç–∞—Å–µ—Ç–∞, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –±–∏—Ç—ã–µ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNWPfxosf18N",
    "outputId": "9d22be0b-db31-4669-8297-2f2998d62e03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seen ids: [0, 1, 2, 3, 4, 5, 6, 7, 8] num: 9\n"
     ]
    }
   ],
   "source": [
    "# –±—ã—Å—Ç—Ä—ã–π sanity-check –ø–æ —á–∞—Å—Ç–∏ train\n",
    "\n",
    "seen = set()\n",
    "for ex in datasets[\"train\"].select(range(2000)):\n",
    "    seen.update(ex[\"ner_tags\"])\n",
    "print(\"seen ids:\", sorted(seen), \"num:\", len(seen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJEhQe1vMbzk"
   },
   "source": [
    "–î–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –≤—ã–≤–µ–¥–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –≤ –≤–∏–¥–µ —Ç–∞–±–ª–∏—Ü—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "Pj1MzSvrelU2",
    "outputId": "a1f4f67b-2109-43f3-bc0e-b8ad71ed1407"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>chunk_tags</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>248</td>\n",
       "      <td>[Jul, 31, ,, Jul, 31, ,, Jul, 31, ,, Jul, 31, ,]</td>\n",
       "      <td>[16, 11, 6, 22, 11, 6, 22, 11, 6, 22, 11, 6]</td>\n",
       "      <td>[11, 12, 0, 11, 12, 0, 11, 12, 0, 11, 12, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7493</td>\n",
       "      <td>[The, man, entered, the, Northcote, College, swimming, pool, changing, sheds, on, Monday, and, told, the, girl, and, a, friend, :, \", You, 're, for, it, now, ., \"]</td>\n",
       "      <td>[12, 21, 38, 12, 22, 22, 21, 21, 39, 24, 15, 22, 10, 38, 12, 21, 10, 12, 21, 8, 0, 28, 41, 15, 28, 30, 7, 0]</td>\n",
       "      <td>[11, 12, 21, 11, 12, 12, 12, 12, 21, 11, 13, 11, 0, 21, 11, 12, 0, 11, 12, 0, 0, 11, 21, 13, 11, 3, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7640</td>\n",
       "      <td>[Rice, options, volume, was, estimated, at, 50, contracts, ,, down, from, 56, Friday, .]</td>\n",
       "      <td>[22, 24, 21, 38, 40, 15, 11, 24, 6, 30, 15, 11, 22, 7]</td>\n",
       "      <td>[11, 12, 12, 21, 22, 13, 11, 12, 0, 3, 13, 11, 11, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13629</td>\n",
       "      <td>[People, were, waiting, for, the, results, to, come, out, before, buying, .]</td>\n",
       "      <td>[24, 38, 39, 15, 12, 24, 35, 37, 33, 15, 39, 7]</td>\n",
       "      <td>[11, 21, 22, 13, 11, 12, 21, 22, 15, 13, 21, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7419</td>\n",
       "      <td>[\", Next, year, ,, the, fiscal, policy, will, have, less, margin, of, freedom, because, the, government, will, have, to, face, commitments, that, it, has, taken, on, under, different, support, schemes, for, the, banks, ,, debtors, and, firms, ,, \", the, brokerage, said, .]</td>\n",
       "      <td>[0, 22, 21, 6, 12, 16, 21, 20, 37, 17, 21, 15, 21, 15, 12, 21, 20, 37, 35, 37, 24, 15, 28, 42, 40, 15, 15, 16, 21, 24, 15, 12, 24, 6, 24, 10, 24, 6, 0, 12, 21, 38, 7]</td>\n",
       "      <td>[0, 11, 12, 0, 11, 12, 12, 21, 22, 11, 12, 13, 11, 17, 11, 12, 21, 22, 22, 22, 11, 17, 11, 21, 22, 3, 13, 11, 12, 12, 13, 11, 12, 12, 12, 12, 12, 0, 0, 11, 12, 21, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13458</td>\n",
       "      <td>[*, Boeing, Co, secures, $, 5.5, billion, in, orders, for, new, ,, larger, 747s, .]</td>\n",
       "      <td>[34, 22, 22, 42, 3, 11, 11, 15, 24, 15, 16, 6, 17, 24, 7]</td>\n",
       "      <td>[0, 11, 12, 21, 11, 12, 12, 13, 11, 13, 11, 12, 12, 12, 0]</td>\n",
       "      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2370</td>\n",
       "      <td>[7., Calvin, Davis, (, U.S., ), 49.49]</td>\n",
       "      <td>[22, 22, 22, 4, 22, 5, 11]</td>\n",
       "      <td>[11, 12, 12, 0, 11, 0, 11]</td>\n",
       "      <td>[0, 1, 2, 0, 5, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5890</td>\n",
       "      <td>[Played, Saturday, :]</td>\n",
       "      <td>[22, 22, 8]</td>\n",
       "      <td>[11, 12, 0]</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10145</td>\n",
       "      <td>[I, do, n't, know, if, I, can, go, any, faster, .]</td>\n",
       "      <td>[28, 41, 30, 37, 15, 28, 20, 37, 12, 17, 7]</td>\n",
       "      <td>[11, 21, 22, 22, 17, 11, 21, 22, 11, 12, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4684</td>\n",
       "      <td>[1., Charmaine, Crooks, (, Canada, ), two, minutes, 00.42, seconds]</td>\n",
       "      <td>[11, 22, 22, 4, 22, 5, 11, 24, 11, 24]</td>\n",
       "      <td>[11, 12, 12, 0, 11, 0, 11, 12, 11, 12]</td>\n",
       "      <td>[0, 1, 2, 0, 5, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"–ù–µ–ª—å–∑—è –≤—ã–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —á–µ–º –µ—Å—Ç—å –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "\n",
    "    # –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º –∏ –∑–∞–º–µ–Ω—è–µ–º —á–∏—Å–ª–∞ –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MQzHovofVH4"
   },
   "source": [
    "### –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ag_z3FtOMr2a"
   },
   "source": [
    "–≠—Ç–æ **—Å–∞–º–∞—è –≤–∞–∂–Ω–∞—è —á–∞—Å—Ç—å**. –ù–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç —Å–ª–æ–≤–∞, –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å —á–∏—Å–ª–∞–º–∏ (ID —Ç–æ–∫–µ–Ω–æ–≤). –ù–∞–º –Ω—É–∂–µ–Ω `Tokenizer`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0M_hWZ2fZFN"
   },
   "source": [
    "–ü–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å —Ç–µ–∫—Å—Ç –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å `Tokenizer`-–æ–º. –û–Ω –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç —Ç–æ–∫–µ–Ω—ã –≤ ID –∏–∑ —Å–ª–æ–≤–∞—Ä—è –º–æ–¥–µ–ª–∏. –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `AutoTokenizer`, –∫–æ—Ç–æ—Ä—ã–π —Å–∞–º –ø–æ–¥—Ç—è–Ω–µ—Ç –Ω—É–∂–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (`distilbert-base-uncased`).\n",
    "\n",
    "> **–í–∞–∂–Ω–æ:** –Ω–∞–º –Ω—É–∂–µ–Ω –∏–º–µ–Ω–Ω–æ \"Fast\" —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (–Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –Ω–∞ Rust), —Ç–∞–∫ –∫–∞–∫ –æ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, —á—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è NER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOgyQ9GjMu9o"
   },
   "source": [
    "> –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `DistilBERT`. –ï–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–∞ –Ω–∞ **–ø–æ–¥—Å–ª–æ–≤–∞ (subwords)**.\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä: —Å–ª–æ–≤–æ `embedding` –º–æ–∂–µ—Ç —Ä–∞–∑–±–∏—Ç—å—Å—è –Ω–∞ `em`, `##bed`, `##ding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_p_d7alvfY2r"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuiJOV2uf_dl"
   },
   "source": [
    "### –ü—Ä–æ–±–ª–µ–º–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è —Å–ª–æ–≤ (Subword Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YSKnZuEgBwT"
   },
   "source": [
    "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞ (subwords). –î–∞–∂–µ –µ—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É–∂–µ —Ä–∞–∑–±–∏—Ç—ã –Ω–∞ —Å–ª–æ–≤–∞ (–∫–∞–∫ —É –Ω–∞—Å), —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –º–æ–∂–µ—Ç —Ä–∞–∑–±–∏—Ç—å –æ–¥–Ω–æ —Å–ª–æ–≤–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsefLVGAgFZV"
   },
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø—Ä–∏–º–µ—Ä:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7anq-RMfU4n",
    "outputId": "debec219-d8ed-4bab-e53c-f459386a5aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokens: ['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n",
      "BERT tokens:     ['[CLS]', 'germany', \"'\", 's', 'representative', 'to', 'the', 'european', 'union', \"'\", 's', 'veterinary', 'committee', 'werner', 'z', '##wing', '##mann', 'said', 'on', 'wednesday', 'consumers', 'should', 'buy', 'sheep', '##me', '##at', 'from', 'countries', 'other', 'than', 'britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞, –≥–¥–µ –µ—Å—Ç—å —Å–ª–æ–∂–Ω–æ–µ —Å–ª–æ–≤–æ\n",
    "example = datasets[\"train\"][4]\n",
    "print(\"Original tokens:\", example[\"tokens\"])\n",
    "\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(\"BERT tokens:    \", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp9nv5WWgJcP"
   },
   "source": [
    "–í–∏–¥–∏—Ç–µ? –°–ª–æ–≤–∞ \"Zwingmann\" –∏ \"sheepmeat\" —Ä–∞–∑–±–∏–ª–∏—Å—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `sheep`, `##me`, `##at`).\n",
    "\n",
    "–≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É: —É –Ω–∞—Å –±—ã–ª–∞ **–æ–¥–Ω–∞ –º–µ—Ç–∫–∞** –¥–ª—è —Å–ª–æ–≤–∞ \"sheepmeat\", –∞ —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å **—Ç—Ä–∏ —Ç–æ–∫–µ–Ω–∞**. –ö–∞–∫ —Ä–∞—Å—Å—Ç–∞–≤–∏—Ç—å –º–µ—Ç–∫–∏?\n",
    "\n",
    "–ö —Å—á–∞—Å—Ç—å—é, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–æ–¥ `word_ids()`, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –æ–±—Ä–∞—Ç–Ω–æ —Å–æ —Å–ª–æ–≤–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ct8MJOexgLhn",
    "outputId": "cb621416-2721-44be-9ae4-ed4d1e21b9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e1C-7vHgOoX"
   },
   "source": [
    "–û–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–π –∂–µ –¥–ª–∏–Ω—ã, —á—Ç–æ –∏ —Ç–æ–∫–µ–Ω—ã:\n",
    "\n",
    "  * `None` –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (–∫–∞–∫ `[CLS]`, `[SEP]`).\n",
    "  * –ò–Ω–¥–µ–∫—Å —Å–ª–æ–≤–∞ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAs3rrMqgn3O"
   },
   "source": [
    "### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –º–µ—Ç–æ–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M_AvKMUgqxT"
   },
   "source": [
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é:\n",
    "\n",
    "1.  –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º —Ç–æ–∫–µ–Ω–∞–º (`None`) –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –º–µ—Ç–∫—É **-100**. –≠—Ç–æ—Ç –∏–Ω–¥–µ–∫—Å –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏–µ–π –ø–æ—Ç–µ—Ä—å (loss function) –≤ PyTorch/TensorFlow –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.\n",
    "2.  –ü–µ—Ä–≤–æ–º—É —Ç–æ–∫–µ–Ω—É —Å–ª–æ–≤–∞ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–µ—Ç–∫—É.\n",
    "3.  –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —á–∞—Å—Ç–µ–π —Å–ª–æ–≤–∞ (—Å–∞–±—Ç–æ–∫–µ–Ω–æ–≤) –º—ã –º–æ–∂–µ–º –ª–∏–±–æ –ø—Ä–∏—Å–≤–æ–∏—Ç—å —Ç—É –∂–µ –º–µ—Ç–∫—É, –ª–∏–±–æ -100. –ú—ã –≤—ã–±–µ—Ä–µ–º –≤–∞—Ä–∏–∞–Ω—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç–∫–∏ (—Ñ–ª–∞–≥ `label_all_tokens = True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0889JRqgthu",
    "outputId": "83cc63bb-d093-47f5-ffa3-3b019ee91386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "# –ø—Ä–∏–º–µ—Ä –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogr2XzpGgv-0"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –¥–µ–ª–∞–µ—Ç —ç—Ç–æ –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞ –¥–∞–Ω–Ω—ã—Ö:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-0QG8-IgzS4"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –±–∞—Ç—á –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n",
    "    # truncation=True –æ–±—Ä–µ–∂–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    # –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–º–µ—Ä—É –≤ –±–∞—Ç—á–µ\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        # –ø–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ \"–∏–Ω–¥–µ–∫—Å —Ç–æ–∫–µ–Ω–∞ -> –∏–Ω–¥–µ–∫—Å —Å–ª–æ–≤–∞\"\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            # —Å–ª—É—á–∞–π 1: –°–ø–µ—Ü—Ç–æ–∫–µ–Ω—ã ([CLS], [SEP]) -> —Å—Ç–∞–≤–∏–º -100\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "\n",
    "            # —Å–ª—É—á–∞–π 2: –≠—Ç–æ –Ω–∞—á–∞–ª–æ –ù–û–í–û–ì–û —Å–ª–æ–≤–∞\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx]) # –ë–µ—Ä–µ–º –º–µ—Ç–∫—É —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞\n",
    "\n",
    "            # —Å–ª—É—á–∞–π 3: –≠—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–æ–≥–æ –∂–µ —Å–ª–æ–≤–∞ (—Å–∞–±—Ç–æ–∫–µ–Ω)\n",
    "            else:\n",
    "                # –µ—Å–ª–∏ label_all_tokens=True, –¥—É–±–ª–∏—Ä—É–µ–º –º–µ—Ç–∫—É, –∏–Ω–∞—á–µ -100\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    # –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –º–µ—Ç–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ4PGbtng1lL"
   },
   "source": [
    "–ü—Ä–∏–º–µ–Ω–∏–º —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –∫–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º —Å—Ä–∞–∑—É —á–µ—Ä–µ–∑ `map`. –ü–∞—Ä–∞–º–µ—Ç—Ä `batched=True` –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "46f10e153bdb4f6f9f63c1770256720a",
      "86cf5838345d4859be33fa781eddbfcc",
      "443a23c321cf41f2b4ce145bc5b397db",
      "eb33f7b9fe054ba3921076189f5df3c1",
      "d60bb7166a8b4f78b9f9c60a4e085b6a",
      "74635bb4064c4a2194c85a707bc9250c",
      "7123fa9826264c5ebd5831ea2749e252",
      "9065d4e45d314f03ab8ec961a5b61349",
      "6275d414df5b41aea18a059f8f1e70d7",
      "d9a4ca4865a94d8e8e08f4e4111e9a60",
      "e2a6299b906447a99c9f3c8f9b022773"
     ]
    },
    "id": "zcs91Jdyg3Rb",
    "outputId": "c1cbec61-c423-4be1-aa36-7c8601a3e3f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f10e153bdb4f6f9f63c1770256720a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9PtmyWNg6C4"
   },
   "source": [
    "### Fine-tuning –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQD7o6HSg8_x"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å `AutoModelForTokenClassification`.\n",
    "–ú—ã —É–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Ç–æ–∫ (`num_labels`) –∏ —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ID \\<-\\> Label, —á—Ç–æ–±—ã –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏ –±—ã–ª —á–∏—Ç–∞–µ–º—ã–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "af476ba845504026914160ac6f498b6e",
      "88e9d52c65a64c72a84972f3bd6b21e0",
      "7a9efcaf64794d0dad751b593ab2438c",
      "681e6fbd9a584885b557eb15c95888e5",
      "dd655e3da6984fd38e552972d9d57b79",
      "92bb4dc3499b4c948511f0f42fb2b8f7",
      "3b9c5a6a5f1b4ed79770e8dfbaac13e0",
      "0e17b5c1d3fb4dfe8d0790b37c880c80",
      "96221df7177e4b64be38cec1410914b0",
      "b2cad4a2035e498ca200776b9b406992",
      "15d9126fad1c4d89866ded877f94fd54"
     ]
    },
    "id": "jDEyVJ1Ug_rx",
    "outputId": "800f3f51-3305-4082-c9df-6d4e5cbb4ad7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af476ba845504026914160ac6f498b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# —Å–ª–æ–≤–∞—Ä–∏ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ID <-> –ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç–∫–∏ (–¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –ø—Ä–∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–µ)\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEIx5vTghB4N"
   },
   "source": [
    "> –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –í—ã —É–≤–∏–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Å–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `vocab_layer_norm`) –±—ã–ª–∏ –æ—Ç–±—Ä–æ—à–µ–Ω—ã, –∞ –Ω–æ–≤—ã–µ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä) –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω–æ. –≠—Ç–æ **–Ω–æ—Ä–º–∞–ª—å–Ω–æ**. –ú—ã –±–µ—Ä–µ–º \"—Ç–µ–ª–æ\" –º–æ–¥–µ–ª–∏ (encoder), –æ–±—É—á–µ–Ω–Ω–æ–µ –Ω–∞ —è–∑—ã–∫–µ, –∏ –∑–∞–º–µ–Ω—è–µ–º \"–≥–æ–ª–æ–≤—É\" –Ω–∞ –Ω–æ–≤—É—é, –∫–æ—Ç–æ—Ä—É—é —Å–µ–π—á–∞—Å –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å –ø–æ–¥ –Ω–∞—à—É –∑–∞–¥–∞—á—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FqkgXSRhMOZ"
   },
   "source": [
    "### Data Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huwRw9gDhN2j"
   },
   "source": [
    "–ù–∞–º –Ω—É–∂–µ–Ω Data Collator, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–±–µ—Ä–µ—Ç –ø—Ä–∏–º–µ—Ä—ã –≤ –±–∞—Ç—á–∏. –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤ –æ–Ω –¥–æ–ª–∂–µ–Ω –¥–µ–ª–∞—Ç—å **padding** –Ω–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö ID, –Ω–æ –∏ –¥–ª—è **–º–µ—Ç–æ–∫** (labels), —á—Ç–æ–±—ã —Ç–µ–Ω–∑–æ—Ä—ã –±—ã–ª–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maRjhIPEiTqH"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE9eGhUshS7Z"
   },
   "source": [
    "\n",
    "### –ú–µ—Ç—Ä–∏–∫–∏ (seqeval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBUx3uobhXza"
   },
   "source": [
    "–û–±—ã—á–Ω–∞—è `accuracy` –ø–ª–æ—Ö–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è NER, —Ç–∞–∫ –∫–∞–∫ –∫–ª–∞—Å—Å `O` (–Ω–µ —Å—É—â–Ω–æ—Å—Ç—å) –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ 90% —Å–ª—É—á–∞–µ–≤. –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –≤–µ–∑–¥–µ `O` –∏ –∏–º–µ—Ç—å –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –±—ã—Ç—å –±–µ—Å–ø–æ–ª–µ–∑–Ω–æ–π.\n",
    "\n",
    "–ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É `seqeval`, –∫–æ—Ç–æ—Ä–∞—è —Å—á–∏—Ç–∞–µ—Ç Precision, Recall –∏ F1-score –Ω–∞ —É—Ä–æ–≤–Ω–µ **—Å—É—â–Ω–æ—Å—Ç–µ–π**, –∞ –Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "–û–±—ã—á–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç evaluate, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –¥–æ–±–∞–≤–ª—é fallback –Ω–∞ load_metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "40d21e6ded164c0a8c494f4c210d6ee9",
      "f7a47daf3a3c4b43a524d819875bb06b",
      "52c1bcbab2bb4e59b1e992d4622aa3f7",
      "639fd70fe2fb461d91227b54a386506e",
      "8d339cb006174871bbf373002a29182d",
      "b2fff40fdcb54f4ab0f37228cdf5d67d",
      "4aacfb2641f24f99bff8abc8111e6207",
      "7a6e05d350114d34b853fd596212e70e",
      "430337706c88491b8ebd27e0bd2577f3",
      "deb6f9f8899a4c3e82d07444c3c988f2",
      "710dce70f7264ce8ad6513e65c5e1603"
     ]
    },
    "id": "NYzDKo8fhSrv",
    "outputId": "7996f7d5-8ffe-4f10-97a1-d03b586df8f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d21e6ded164c0a8c494f4c210d6ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import evaluate\n",
    "    seqeval = evaluate.load(\"seqeval\")\n",
    "except Exception:\n",
    "    from datasets import load_metric\n",
    "    seqeval = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    # —É seqeval –±—ã–≤–∞—é—Ç —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä—Å–∏–∏, –Ω–æ overall_* –æ–±—ã—á–Ω–æ –µ—Å—Ç—å\n",
    "    return {\n",
    "        \"precision\": results.get(\"overall_precision\", 0.0),\n",
    "        \"recall\": results.get(\"overall_recall\", 0.0),\n",
    "        \"f1\": results.get(\"overall_f1\", 0.0),\n",
    "        \"accuracy\": results.get(\"overall_accuracy\", 0.0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v38mXwgyhdNd"
   },
   "source": [
    "### –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdaBtSyjhgFr"
   },
   "source": [
    "–ú—ã –≥–æ—Ç–æ–≤—ã –æ–±—É—á–∞—Ç—å\\! –î–æ–±–∞–≤–∏–º `metric_callback`. –û–±—É—á–µ–Ω–∏–µ (Fine-tuning) –Ω–∞ PyTorch —á–µ—Ä–µ–∑ Trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "b-qMnX22hcyl",
    "outputId": "3160364e-90cb-4c20-fc01-d6ed66bcf64d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-4124859767.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 01:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>0.073935</td>\n",
       "      <td>0.894765</td>\n",
       "      <td>0.919790</td>\n",
       "      <td>0.907105</td>\n",
       "      <td>0.979030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.059971</td>\n",
       "      <td>0.924810</td>\n",
       "      <td>0.937018</td>\n",
       "      <td>0.930874</td>\n",
       "      <td>0.983415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027400</td>\n",
       "      <td>0.060505</td>\n",
       "      <td>0.928848</td>\n",
       "      <td>0.939031</td>\n",
       "      <td>0.933912</td>\n",
       "      <td>0.984479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.0605047307908535,\n",
       " 'eval_precision': 0.9288480690494633,\n",
       " 'eval_recall': 0.9390312115449155,\n",
       " 'eval_f1': 0.9339118825100133,\n",
       " 'eval_accuracy': 0.9844790061480293,\n",
       " 'eval_runtime': 2.6793,\n",
       " 'eval_samples_per_second': 1213.021,\n",
       " 'eval_steps_per_second': 76.14,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "num_train_epochs = 3 # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ö–æ–¥–æ–≤ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"./{task}_distilbert_finetuned\", # –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–æ–¥–µ–ª—å\n",
    "    learning_rate=2e-5, # —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (–æ–±—ã—á–Ω–æ 2e-5 ... 5e-5)\n",
    "    weight_decay=0.01, # —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "\n",
    "    eval_strategy=\"epoch\", # –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n",
    "    save_strategy=\"epoch\", # —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50, # –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –ª–æ—Å—Å –∫–∞–∂–¥—ã–µ 50 —à–∞–≥–æ–≤\n",
    "    report_to=\"none\", # –æ—Ç–∫–ª—é—á–∞–µ–º wandb –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    processing_class=tokenizer, # (–∏–ª–∏ tokenizer=tokenizer –≤ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö)\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D776y-tchlnN"
   },
   "source": [
    "### –ò–Ω—Ñ–µ—Ä–µ–Ω—Å (–ü—Ä–æ–≤–µ—Ä–∫–∞)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA1no-5LhoDp"
   },
   "source": [
    "–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∏–º –º–æ–¥–µ–ª—å. –ú—ã –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –µ—ë —á–µ—Ä–µ–∑ Pipeline API, –∫–æ—Ç–æ—Ä—ã–π —Å–∫—Ä–æ–µ—Ç –æ—Ç –Ω–∞—Å –≤—Å—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jFBZfQ0il1g",
    "outputId": "708bd6db-01f6-4afa-d3e4-37c6eba5fbae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Steve Jobs presented the first iPhone in San Francisco in 2007.\n",
      "\n",
      "Predictions:\n",
      "PER: steve jobs (score: 0.97)\n",
      "MISC: iphone (score: 0.91)\n",
      "LOC: san francisco (score: 0.99)\n"
     ]
    }
   ],
   "source": [
    "# –ë—ã—Å—Ç—Ä–æ —á–µ—Ä–µ–∑ pipeline (PyTorch)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\", # –í–∞–∂–Ω–æ: —Å–∫–ª–µ–∏–≤–∞–µ—Ç B-PER –∏ I-PER –≤ –æ–¥–Ω—É —Å—É—â–Ω–æ—Å—Ç—å\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "sample_sentence = \"Steve Jobs presented the first iPhone in San Francisco in 2007.\"\n",
    "\n",
    "results = token_classifier(sample_sentence)\n",
    "print(\"Input:\", sample_sentence)\n",
    "print(\"\\nPredictions:\")\n",
    "for res in results:\n",
    "    print(f\"{res['entity_group']}: {res['word']} (score: {res['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYBtXw5PhqWv",
    "outputId": "4eec0ca1-caab-4f73-fda1-915df6d801ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       [CLS] -> O\n",
      "       steve -> B-PER\n",
      "        jobs -> I-PER\n",
      "   presented -> O\n",
      "         the -> O\n",
      "       first -> O\n",
      "      iphone -> B-MISC\n",
      "          in -> O\n",
      "         san -> B-LOC\n",
      "   francisco -> I-LOC\n",
      "          in -> O\n",
      "        2007 -> O\n",
      "           . -> O\n",
      "       [SEP] -> O\n"
     ]
    }
   ],
   "source": [
    "# —Ä—É—á–Ω–æ–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å (–±–µ–∑ pipeline)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() # –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ (–≤—ã–∫–ª dropout –∏ —Ç.–¥.)\n",
    "\n",
    "text = \"Steve Jobs presented the first iPhone in San Francisco in 2007.\"\n",
    "# —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∏ –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã PyTorch\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits  # —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: [1, seq_len, num_labels]\n",
    "\n",
    "# –ø–æ–ª—É—á–∞–µ–º ID –∫–ª–∞—Å—Å–∞ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é\n",
    "pred_ids = logits.argmax(dim=-1)[0].cpu().tolist()\n",
    "input_ids = inputs[\"input_ids\"][0].cpu().tolist()\n",
    "\n",
    "# –¥–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–∫—Å—Ç\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "# –¥–µ–∫–æ–¥–∏—Ä—É–µ–º ID –∫–ª–∞—Å—Å–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏—è (PER, ORG...)\n",
    "labels = [model.config.id2label[i] for i in pred_ids]\n",
    "\n",
    "print(\"\\n–ü–æ—Ç–æ–∫–µ–Ω–Ω—ã–π –≤—ã–≤–æ–¥:\")\n",
    "for t, y in zip(tokens, labels):\n",
    "    print(f\"{t:>12} -> {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTUvxGmjcBXk"
   },
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç pipeline –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–ª —Ç–æ–∫–µ–Ω—ã –∏ –≤—ã–¥–∞–ª –Ω–∞–º —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π —Å –∏—Ö —Ç–∏–ø–∞–º–∏ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOngYQ7UzJfB"
   },
   "source": [
    "### –ü–æ–º–µ–Ω—è–µ–º task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GD_hpp7Gx_N6"
   },
   "outputs": [],
   "source": [
    "task = \"pos\"\n",
    "label_col = f\"{task}_tags\"   # \"pos_tags\"\n",
    "\n",
    "tags_feat = datasets[\"train\"].features[label_col]\n",
    "\n",
    "if hasattr(tags_feat, \"feature\") and hasattr(tags_feat.feature, \"names\"):\n",
    "    label_list = tags_feat.feature.names\n",
    "else:\n",
    "    # –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–µ–º –∏–º–µ–Ω–∞ L0..L{K-1} –ø–æ —á–∏—Å–ª—É –∫–ª–∞—Å—Å–æ–≤, –Ω–∞–π–¥–µ–Ω–Ω–æ–º—É –≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "    all_ids = set()\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        for ex in datasets[split]:\n",
    "            all_ids.update(ex[label_col])\n",
    "    num_labels = max(all_ids) + 1\n",
    "    label_list = [f\"L{i}\" for i in range(num_labels)]\n",
    "\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2C-0K_KdzEji"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    for p_seq, l_seq in zip(preds, labels):\n",
    "        for p, l in zip(p_seq, l_seq):\n",
    "            if l != -100:\n",
    "                y_true.append(int(l))\n",
    "                y_pred.append(int(p))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc.compute(predictions=y_pred, references=y_true)[\"accuracy\"],\n",
    "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GoHV4Uz7zx8t"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfoclAatzy_T"
   },
   "outputs": [],
   "source": [
    "ta_params = inspect.signature(TrainingArguments.__init__).parameters\n",
    "\n",
    "ta_kwargs = dict(\n",
    "    output_dir=\"./pos_distilbert_pt\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "if \"eval_strategy\" in ta_params:\n",
    "    ta_kwargs[\"eval_strategy\"] = \"epoch\"\n",
    "else:\n",
    "    ta_kwargs[\"evaluation_strategy\"] = \"epoch\"\n",
    "\n",
    "args = TrainingArguments(**ta_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j09-1irGz0TP"
   },
   "outputs": [],
   "source": [
    "trainer_kwargs = dict(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_params = inspect.signature(Trainer.__init__).parameters\n",
    "if \"processing_class\" in trainer_params:\n",
    "    trainer_kwargs[\"processing_class\"] = tokenizer\n",
    "else:\n",
    "    trainer_kwargs[\"tokenizer\"] = tokenizer\n",
    "\n",
    "trainer = Trainer(**trainer_kwargs)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtnE2BT8zWzb"
   },
   "outputs": [],
   "source": [
    "pos_tagger = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=trainer.model,\n",
    "    tokenizer=tokenizer,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "sentence = \"Steve Jobs presented the first iPhone in San Francisco in 2007.\"\n",
    "out = pos_tagger(sentence)\n",
    "\n",
    "for r in out[:25]:\n",
    "    print(r[\"word\"], \"->\", r[\"entity_group\"], f\"({r['score']:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SOngYQ7UzJfB"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
